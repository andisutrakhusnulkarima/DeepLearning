{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnj2THVRrZDuoev94rGWkj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andisutrakhusnulkarima/DeepLearning/blob/main/Tugas_Deep_Week_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_UBDnHr6P9-",
        "outputId": "2450c238-9f7c-4344-ea49-fecbe56f8ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-08 13:22:21--  https://raw.githubusercontent.com/farrelrassya/teachingMLDL/main/02.%20Deep%20Learning/Dataset/Infrared.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 244181 (238K) [text/plain]\n",
            "Saving to: ‘Infrared.csv’\n",
            "\n",
            "Infrared.csv        100%[===================>] 238.46K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-03-08 13:22:21 (4.66 MB/s) - ‘Infrared.csv’ saved [244181/244181]\n",
            "\n",
            "Epoch [50/500], Loss: 0.3551\n",
            "Epoch [100/500], Loss: 0.2662\n",
            "Epoch [150/500], Loss: 0.2253\n",
            "Epoch [200/500], Loss: 0.2196\n",
            "Epoch [250/500], Loss: 0.2074\n",
            "Epoch [300/500], Loss: 0.1952\n",
            "Epoch [350/500], Loss: 0.1847\n",
            "Epoch [400/500], Loss: 0.1821\n",
            "Epoch [450/500], Loss: 0.1558\n",
            "Epoch [500/500], Loss: 0.1648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "PyTorch Model Evaluation:\n",
            "MSE: 0.0492, RMSE: 0.2217, R2 Score: 0.7665\n",
            "TensorFlow Model Evaluation:\n",
            "MSE: 0.0483, RMSE: 0.2199, R2 Score: 0.7704\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "!wget -O Infrared.csv \"https://raw.githubusercontent.com/farrelrassya/teachingMLDL/main/02.%20Deep%20Learning/Dataset/Infrared.csv\"\n",
        "\n",
        "df = pd.read_csv('Infrared.csv')\n",
        "df\n",
        "\n",
        "\n",
        "# Handle missing values using SimpleImputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df[df.select_dtypes(include=[np.number]).columns] = imputer.fit_transform(df.select_dtypes(include=[np.number]))\n",
        "\n",
        "# Ensure categorical columns exist before encoding\n",
        "categorical_columns = ['Gender', 'Age', 'Ethnicity']\n",
        "categorical_columns = [col for col in categorical_columns if col in df.columns]\n",
        "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Select features and target\n",
        "X = df.drop(columns=['aveOralM'])\n",
        "y = df['aveOralM']\n",
        "\n",
        "# Normalize features and target\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "X = scaler_X.fit_transform(X)\n",
        "y = scaler_y.fit_transform(y.to_numpy().reshape(-1, 1)).flatten()\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to tensors (PyTorch)\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Define Improved PyTorch Model with Hyperparameter Tuning\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 512)  # Increased units\n",
        "        self.fc2 = nn.Linear(512, 256)        # Increased units\n",
        "        self.fc3 = nn.Linear(256, 128)        # Increased units\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)        # Adjusted dropout rate to 0.3\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model with increased complexity\n",
        "input_dim = X_train.shape[1]\n",
        "model = NeuralNetwork(input_dim)\n",
        "\n",
        "# Loss and optimizer with tuned learning rate\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)  # Adjusted learning rate and weight decay\n",
        "\n",
        "# Train model with tuned hyperparameters\n",
        "num_epochs = 500  # Increased epochs for better training\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch+1) % 50 == 0:  # Print every 50 epochs\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Predictions (ensure that model is in evaluation mode during inference)\n",
        "model.eval()\n",
        "y_pred_pytorch = model(X_test_tensor).detach().numpy()\n",
        "\n",
        "# TensorFlow Model with Hyperparameter Tuning\n",
        "tf_model = keras.Sequential([\n",
        "    keras.layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)),  # Increased units\n",
        "    keras.layers.Dropout(0.3),  # Adjusted dropout rate to 0.3\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "tf_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='mse')  # Adjusted learning rate\n",
        "\n",
        "# Train TensorFlow model with early stopping\n",
        "es = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)  # Increased patience\n",
        "tf_model.fit(X_train, y_train, epochs=500, batch_size=64, verbose=0, validation_data=(X_test, y_test), callbacks=[es])\n",
        "\n",
        "# Predictions\n",
        "y_pred_tf = tf_model.predict(X_test)\n",
        "\n",
        "# Inverse transform results\n",
        "y_pred_pytorch = scaler_y.inverse_transform(y_pred_pytorch)\n",
        "y_pred_tf = scaler_y.inverse_transform(y_pred_tf)\n",
        "y_test = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Evaluation metrics\n",
        "mse_pytorch = mean_squared_error(y_test, y_pred_pytorch)\n",
        "rmse_pytorch = np.sqrt(mse_pytorch)\n",
        "r2_pytorch = r2_score(y_test, y_pred_pytorch)\n",
        "\n",
        "mse_tf = mean_squared_error(y_test, y_pred_tf)\n",
        "rmse_tf = np.sqrt(mse_tf)\n",
        "r2_tf = r2_score(y_test, y_pred_tf)\n",
        "\n",
        "# Print evaluation results\n",
        "print(\"PyTorch Model Evaluation:\")\n",
        "print(f'MSE: {mse_pytorch:.4f}, RMSE: {rmse_pytorch:.4f}, R2 Score: {r2_pytorch:.4f}')\n",
        "\n",
        "print(\"TensorFlow Model Evaluation:\")\n",
        "print(f'MSE: {mse_tf:.4f}, RMSE: {rmse_tf:.4f}, R2 Score: {r2_tf:.4f}')\n"
      ]
    }
  ]
}